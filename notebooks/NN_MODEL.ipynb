{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FZ3uPDa-sENJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Importer la fonction de splitting des données de scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Importer Dataset de torch.utils.data\n",
    "from torch.utils.data import Dataset\n",
    "# Importer DataLoader de torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "# Importer le module nn\n",
    "import torch.nn as nn\n",
    "# Définir une fonction d'optimisation des coût: Adam par exemple. On devra définir un learning rate. On choisira 0.001.\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une classe qui hérite de Dataset et redéfinit les méthodes \n",
    "class Covid_Dataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(Covid_Dataset, self)\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qe3HFD33sEYm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Data-FakeRealCOVID.xlsx\")\n",
    "newDF = pd.read_csv(\"newDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.hist(xlabelsize=20,figsize=[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBhZ6rdYsiq3"
   },
   "outputs": [],
   "source": [
    "newDF = newDF.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "wOV71dtes3kg",
    "outputId": "8ba24130-679a-4e54-e35a-3540a77ce486"
   },
   "outputs": [],
   "source": [
    "newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redDim(dfVec,seuil1,seuil2):\n",
    "    subDf = dfVec[dfVec != 0]\n",
    "    map = subDf.count(axis = 0) <= seuil1 \n",
    "    map2 = subDf.count(axis = 0) >= (dfVec.shape[0] - seuil2) \n",
    "    resultDf = dfVec.drop(dfVec.columns[map+map2],axis=1)\n",
    "    columns_dropped=dfVec.columns[map+map2]\n",
    "    \n",
    "    return resultDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzM25Jlb61y9",
    "outputId": "e918e3de-3d8d-4df6-f795-2540e0dfa482"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for label in df.label.to_numpy():\n",
    "  if label == 'real':\n",
    "    labels.append(1)\n",
    "  else:\n",
    "    labels.append(0)\n",
    "targets=torch.tensor(labels)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWC7l7AlrRvY",
    "outputId": "0e17615b-bd57-4ef9-9464-487849f545cf"
   },
   "outputs": [],
   "source": [
    "targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cRVsJ5P61wJ"
   },
   "outputs": [],
   "source": [
    "data=torch.tensor(newDF.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFo0D2UDrL9f",
    "outputId": "4dd9c4d3-3044-4df3-f7b7-80ac8ce04d7c"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LqR9Z4fsEbQ"
   },
   "outputs": [],
   "source": [
    "# Importer la fonction de splitting des données de scikit learn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9FvJq-RJxxX",
    "outputId": "db9716d2-df2b-41b8-a902-529ce0debb9a"
   },
   "outputs": [],
   "source": [
    "# Créer 4 tensors en résultat du splitting: données d'apprentissage, données de test, labels d'apprentissage, et labels de test  \n",
    "atrain_data, test_data, atrain_targets, test_targets = train_test_split(data, targets, test_size=0.2)\n",
    "atrain_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avlRzUHBsEd0",
    "outputId": "c28991ec-d8a0-4919-94d8-4e87fb9c73ce"
   },
   "outputs": [],
   "source": [
    "# Créer 4 tensors en résultat du splitting: données d'apprentissage, données de validation, labels d'apprentissage, et labels de validation  \n",
    "train_data, validation_data, train_targets, validation_targets = train_test_split(atrain_data, atrain_targets, test_size=1000)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7D9yvLbsEjV",
    "outputId": "3eab84ea-06aa-4025-9aa5-b66a43a35551"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Afficher la taille de chaque tensor\n",
    "print(train_data.shape, train_targets.shape)\n",
    "print(validation_data.shape, validation_targets.shape)\n",
    "print(test_data.shape,test_targets.shape)\n",
    "print(train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoS4SEElK18d"
   },
   "outputs": [],
   "source": [
    "# Importer Dataset de torch.utils.data\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p00R4rbYLHy6"
   },
   "outputs": [],
   "source": [
    "# Créer une classe qui hérite de Dataset et redéfinit les méthodes \n",
    "class Covid_Dataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super(Covid_Dataset, self)\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5NcCk_gLR0P"
   },
   "outputs": [],
   "source": [
    "# Créer les 3 objets en instantiant votre classe\n",
    "train_dataset = Covid_Dataset(train_data, train_targets)\n",
    "test_dataset = Covid_Dataset(test_data, test_targets)\n",
    "validation_dataset = Covid_Dataset(validation_data, validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnltqtTlLlSP"
   },
   "outputs": [],
   "source": [
    "# Importer DataLoader de torch.utils.data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIParFTvLn8i"
   },
   "outputs": [],
   "source": [
    "# Créer une variable pour la taille du batch\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiBGAcYgL5GV"
   },
   "outputs": [],
   "source": [
    "# Créer les objets DataLoader pour vos datasets d'apprentissage, test et validation en lui donner la taille du batch convenue\n",
    "\n",
    "train_DL = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_DL = DataLoader(test_dataset, batch_size=batch_size)\n",
    "validation_DL = DataLoader(validation_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzmpmmyEf_pt",
    "outputId": "e2bc1ab7-c5cb-4836-fcc9-2556fb26445d"
   },
   "outputs": [],
   "source": [
    "len(train_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yQIn6kpgGtG"
   },
   "outputs": [],
   "source": [
    "# Importer le module nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdLwPkOSj20C"
   },
   "outputs": [],
   "source": [
    "# En utilisant Sequential(), créer un modèle avec l'architecture susmentionnée\n",
    "CovidNN = nn.Sequential(nn.Linear(train_data.shape[1], 64),nn.ReLU(),nn.Linear(64, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKcOOgT6mLLV"
   },
   "outputs": [],
   "source": [
    "# Définir la fonction du coût. On peut choisir CrossEntropyLoss\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eK8iWgXm1NK"
   },
   "outputs": [],
   "source": [
    "# Définir une fonction d'optimisation des coût: Adam par exemple. On devra définir un learning rate. On choisira 0.001.\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(CovidNN.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "qR_wViYbrfUj",
    "outputId": "ae8db469-bcba-4e6d-cc12-b4859cb38e86"
   },
   "outputs": [],
   "source": [
    "for data,targets in train_DL:\n",
    "  print(data)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "2NrocaPSpPet",
    "outputId": "8e4cd098-8f2f-418b-d3a6-800b197605d3"
   },
   "outputs": [],
   "source": [
    "# Créer une boucle sur les epochs:\n",
    "def training(model,train_DL,validation_DL,nb_epochs,optimizer,loss_function):\n",
    "    for i in range(nb_epochs):\n",
    "        # Spécifier qu'on est sur le mode entraînement\n",
    "        model.train()\n",
    "        # initialiser notre coût d'apprentissage à 0.0\n",
    "        cout_appr = 0\n",
    "        # Boucler sur les minibatchs des données d'entaînement (les données et leurs targets):\n",
    "        for data,targets in train_DL:    \n",
    "            # le vecteur des labels prédites par le modèle est le résultat de l'application du modèle sur le minibatch en cours. \n",
    "            output = model(data.float())\n",
    "            # Calculer le coût en comparant les labels prédits aux targets du minibatch\n",
    "            loss = loss_function(output,targets)\n",
    "            # Backpropagation: \n",
    "            # Réinitialiser l'optimiseur\n",
    "            optimizer.zero_grad()\n",
    "            # Faire la backpropagation\n",
    "            loss.backward()\n",
    "            # Effectuer un pas d'optimisation\n",
    "            optimizer.step()\n",
    "            # Mettre à jour votre coût d'apprentissage en lui ajoutant le coût du data batch\n",
    "            cout_appr += loss.item()\n",
    "        # A la sortie de la boucle de l'entraînement, on calcule le coût moyen pour toutes les données training\n",
    "        cout_moyen = cout_appr/len(train_DL.dataset)\n",
    "        print('Train_Loss:',cout_moyen)\n",
    "        # Initiliser le coût de validation à 0.0\n",
    "        cout_valid = 0\n",
    "        # Initialiser le nombre de prévisions correctes à 0\n",
    "        prevision_correcte = 0\n",
    "        # Spécifier qu'on est sur le mode d'évaluation\n",
    "        model.eval()\n",
    "        # Indiquer à Pytorch qu'on ne va pas faire de Gradient descent (comme on est dans l'évaluation)\n",
    "        with torch.no_grad():\n",
    "            # Boucler sur les minibatchs des données de validation (les données et leurs targets):\n",
    "            for data,targets in validation_DL:  \n",
    "                # le vecteur des labels prédites par le modèle est le résultat de l'application du modèle sur le minibatch en cours. \n",
    "                output = model(data.float())\n",
    "                # Calculer le coût en comparant les labels prédits aux targets du minibatch\n",
    "                loss = loss_function(output,targets)\n",
    "                # Mettre à jour votre coût de validation en lui ajoutant le coût du data batch\n",
    "                cout_valid += loss.item()\n",
    "                # Mettre à jour le nombre de prévision correctes en y ajoutant le nombre des bonnes prévision sur ce batch\n",
    "                # On y compare le label prédit avec le labels du minibatch. \n",
    "                # Penser à utiliser argmax pour avoir la prévision finale à partir du vecteur de prévision\n",
    "                #prevision_correcte += len(output[output == targets])\n",
    "                prevision_correcte += torch.sum((torch.argmax(output, dim=1) == targets)).item()\n",
    "            # A la sortie de cette boucle, calculer le coût moyen de validation\n",
    "            cout_valid_moyenne = cout_valid/len(validation_DL.dataset)\n",
    "            print('Valid_Loss:',cout_valid_moyenne)\n",
    "            # Calculer la précision: la moyenne des prévisions correctes sur l'ensemble des observations dans le dataset validation \n",
    "            prevision_correcte_moyenne = prevision_correcte/len(validation_DL.dataset)\n",
    "            print('Accuracy:',prevision_correcte_moyenne*100,'%\\n')\n",
    "            \n",
    "        # Afficher pour chaque itération le coût d'entraînement, le coût de validation, et la précision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CovidNN.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(CovidNN,train_DL,validation_DL,9,optimizer,loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliser le coût de test à 0.0\n",
    "cout_test = 0\n",
    "# Initialiser le nombre de prévisions correctes à 0\n",
    "prevision_correcte = 0\n",
    "with torch.no_grad():\n",
    "    # Boucler sur les minibatchs des données de test (les données et leurs targets):\n",
    "    for data,targets in test_DL:  \n",
    "        # le vecteur des labels prédites par le modèle est le résultat de l'application du modèle sur le minibatch en cours. \n",
    "        output = CovidNN(data.float())\n",
    "        # Calculer le coût en comparant les labels prédits aux targets du minibatch\n",
    "        loss = loss_function(output,targets)\n",
    "        # Mettre à jour votre coût de test en lui ajoutant le coût du data batch\n",
    "        cout_test += loss.item()\n",
    "        # Mettre à jour le nombre de prévision correctes en y ajoutant le nombre des bonnes prévision sur ce batch\n",
    "        # On y compare le label prédit avec le labels du minibatch. \n",
    "        # Penser à utiliser argmax pour avoir la prévision finale à partir du vecteur de prévision\n",
    "        #prevision_correcte += len(output[output == targets])\n",
    "        prevision_correcte += torch.sum((torch.argmax(output, dim=1) == targets)).item()\n",
    "    # A la sortie de cette boucle, calculer le coût moyen de test\n",
    "    cout_test_moyenne = cout_test/len(test_dataset)\n",
    "\n",
    "    # Calculer la précision: la moyenne des prévisions correctes sur l'ensemble des observations dans le dataset test \n",
    "    prevision_correcte_moyenne = prevision_correcte/len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9088785046728972"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevision_correcte_moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1284"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1284"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_DL.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarder le modèle dans un fichier pickle\n",
    "#torch.save(CovidNN,'CovidNN.pkl')\n",
    "#torch.save(CovidNN,'interface_graphique/CovidNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model,test_DL,loss_function):\n",
    "    # Initiliser le coût de test à 0.0\n",
    "    cout_test = 0\n",
    "    # Initialiser le nombre de prévisions correctes à 0\n",
    "    prevision_correcte = 0\n",
    "    with torch.no_grad():\n",
    "        # Boucler sur les minibatchs des données de test (les données et leurs targets):\n",
    "        for data,targets in test_DL:  \n",
    "            # le vecteur des labels prédites par le modèle est le résultat de l'application du modèle sur le minibatch en cours. \n",
    "            output = model(data.float())\n",
    "            # Calculer le coût en comparant les labels prédits aux targets du minibatch\n",
    "            loss = loss_function(output,targets)\n",
    "            # Mettre à jour votre coût de test en lui ajoutant le coût du data batch\n",
    "            cout_test += loss.item()\n",
    "            # Mettre à jour le nombre de prévision correctes en y ajoutant le nombre des bonnes prévision sur ce batch\n",
    "            # On y compare le label prédit avec le labels du minibatch. \n",
    "            # Penser à utiliser argmax pour avoir la prévision finale à partir du vecteur de prévision\n",
    "            #prevision_correcte += len(output[output == targets])\n",
    "            prevision_correcte += torch.sum((torch.argmax(output, dim=1) == targets)).item()\n",
    "        # A la sortie de cette boucle, calculer le coût moyen de test\n",
    "        cout_test_moyenne = cout_test/len(test_DL.dataset)\n",
    "\n",
    "        # Calculer la précision: la moyenne des prévisions correctes sur l'ensemble des observations dans le dataset test \n",
    "        prevision_correcte_moyenne = prevision_correcte/len(test_DL.dataset)\n",
    "        print(\"Testing results :\\nLoss : \",cout_test_moyenne,\"\\nAccuracy : \",prevision_correcte_moyenne*100,\"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(dataDF,targets,batch_size,neuronesNb,learning_rate,epochs,seuil1=0,seuil2=0):\n",
    "    \n",
    "    newDF = redDim(dataDF,seuil1,seuil2)\n",
    "    data=torch.tensor(newDF.to_numpy())\n",
    "\n",
    "\n",
    "    # Créer 4 tensors en résultat du splitting: données d'apprentissage, données de test, labels d'apprentissage, et labels de test  \n",
    "    atrain_data, test_data, atrain_targets, test_targets = train_test_split(data, targets, test_size=0.2)\n",
    "\n",
    "    # Créer 4 tensors en résultat du splitting: données d'apprentissage, données de validation, labels d'apprentissage, et labels de validation  \n",
    "    train_data, validation_data, train_targets, validation_targets = train_test_split(atrain_data, atrain_targets, test_size=1000)\n",
    "\n",
    "    # Créer les 3 objets en instantiant votre classe\n",
    "    train_dataset = Covid_Dataset(train_data, train_targets)\n",
    "    test_dataset = Covid_Dataset(test_data, test_targets)\n",
    "    validation_dataset = Covid_Dataset(validation_data, validation_targets)\n",
    "\n",
    "\n",
    "    # Créer les objets DataLoader pour vos datasets d'apprentissage, test et validation en lui donner la taille du batch convenue\n",
    "\n",
    "    train_DL = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_DL = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    validation_DL = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "\n",
    "    # En utilisant Sequential(), créer un modèle avec l'architecture susmentionnée\n",
    "    CovidNN = nn.Sequential(nn.Linear(train_data.shape[1], neuronesNb),nn.ReLU(),nn.Linear(neuronesNb, 2))\n",
    "\n",
    "    # Définir la fonction du coût. On peut choisir CrossEntropyLoss\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(CovidNN.parameters(), lr=learning_rate)\n",
    "    \n",
    "\n",
    "    for layer in CovidNN.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    training(CovidNN,train_DL,validation_DL,epochs,optimizer,loss_function)\n",
    "\n",
    "    testModel(CovidNN,test_DL,loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = createModel(newDF,0,9000,64,9,0.001,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = createModel(newDF,targets,32,64,0.0001,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarder le modèle dans un fichier pickle\n",
    "#modelFileName='CovidNN.tkl'\n",
    "#torch.save(CovidNN,modelFileName)\n",
    "#torch.save(CovidNN,'interface_graphique/'+modelFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NN_MODEL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
